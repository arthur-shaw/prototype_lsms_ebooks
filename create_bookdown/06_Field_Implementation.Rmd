# Chapter 6: Field Implementation

Agricultural surveys may be implemented to achieve various objectives, and these objectives ought to be considered when designing and fielding data collection efforts. NSOs, which are common implementing agencies for agricultural surveys, may seek to use agricultural surveys to produce estimates of crop production or monitor changes in agricultural production over time. These objectives will have implications on the survey design, as estimation of crop production may warrant a cross-sectional design with a larger sample in order to achieve estimates at the desired level of representativeness, while an objective of monitoring and understanding the dynamics of the agricultural sector warrants a panel approach. These objectives and the implications on survey design all need to be considered, while also balancing the often-binding resource constraints and wider mandate of the agency.

This chapter discusses practical considerations for implementing agricultural surveys, with consideration for the primary objectives and constraints faced by implementing agencies, building on the experience of the LSMS-ISA. This chapter primarily focuses on implementation by or in collaboration with NSOs, but many of the principles and challenges of collaboration are instructive for other national collaborations designed to produce data. For information on household surveys costs conducted in partnership with NSOs around the globe, Kilic et al. (2017) summarizes costs and lessons learned from such collaborations.

## Fieldwork Implementation Tradeoffs and Survey Design Choices

Survey fieldwork is a costly and complex operation. Here we discuss various design and implementation decisions that are to be considered in order to achieve the survey objectives while balancing data quality with resource constraints that are common to NSOs and other implementing agencies. These decision points, in which tradeoffs between data quality and implementation cost are present, include but are not limited to the following:

-   Number of survey visits

-   Sample size

-   Question translation

-   Integration of objective measures

-   Survey content and questionnaire design

-   Mode of data collection

-   Enumerator recruitment, training, and supervision

The reference questionnaire in Appendix I, as well as the discussion in previous chapters, promotes interviews being split up into two visits whereby households are visited once following planting and again following harvest. This approach is recommended as it shortens the recall period for planting activities and splits the respondent burden across multiple visits. However, the feasibility of this approach depends on two things: (i) the agricultural calendar of the given country, and (ii) the resource constraints and parallel survey operations of the implementing agency which may further strain resource availability. On the former, if a country has multiple cropping seasons per year, post-planting and post-harvest visits may not be realistic for every cropping season, and depending on the agricultural calendar, recall periods may be reduced in these multi-season years supporting a case for only a post-harvest visit for each season. Resource constraints in terms of funding and/or human resources may also prohibit the implementation of a two-visit survey structure, in which aggregation of data collection efforts into a single post-harvest visit would be the alternative. If resources allow, more frequent visits may be implemented to reduce recall bias.

The objectives of the survey will also inform the sample size required. For operations aimed at highly precise production estimates representative of small administrative areas, a large sample size will likely be needed, depending on the number of key crops and heterogeneity of the sample areas. For example, Ethiopia's 2015-16 Annual Agricultural Sample Survey included a sample of more than 44,000 households, while the LSMS-ISA supported Ethiopia Socioeconomic Survey panel in the same year was implemented on a sample of roughly 5,000 households.[^8] Tradeoffs will be necessary between the detail of the survey instrument and the sample size in order to accommodate resource constraints of the implementing agency. The reference questionnaire provided in Appendix I, for example, includes highly detailed information on the drivers of production that may not be feasible/realistic for implementation in large sample sizes given the time it takes to administer such a survey.

There is also a tradeoff between carefully worded questions and easily understandable questions. While survey designers may be inclined to phrase questions in a very precise manner to get at the exact data they are seeking, this specific phrasing may either be difficult to understand by respondents or lost in translation. Unless the questionnaire is originally designed in the language in which it will be administered, translation will be necessary to account for the language, terms, and concepts of the local context. Back translation, wherein the questionnaire is translated to the local language, and then back to the original language, is recommended to ensure proper translation. Piloting of the questionnaire will also serve to flag incorrect translations or context-specific concepts that are not appropriately reflected in the questionnaire.

Significant tradeoffs exist around the measurement methods employed for specific topics. As discussed previously, systematic bias is evident in the respondent reporting of key agricultural variables such as land area and crop production. These biases can be mitigated by the integration of objective measures into survey operations. These objective, or pseudo-objective, measures may include the use of GPS for area measurement, crop-cutting for measurement of crop production, soil sampling for soil quality, etc. These measures have been shown to dramatically improve data quality, though they do come at a cost. Costs include the procurement of relevant equipment, training on the measures, and additional fieldwork time. The timing of visits should also be considered when determining which objective measures to integrate into a survey, as some are time sensitive and cannot be completed in a single-visit survey (such as crop cutting). Where integration of these measurements on the full sample is not possible due to resource constraints, a combination of sub-sampling for objective measurement and imputation techniques can be used to improve data quality across the sample with limited financial investment. Kilic et al. (2017), for example, illustrate how multiple imputation techniques can be used to impute improved measures of plot area for observations where GPS measurement was not conducted.

A significant discussion with implementation partners is the survey content and questionnaire design choices which may increase field time and interview complexity. Our discussion throughout this volume was to document best practice where possible and provide questionnaire designers with information about survey design choices. We fully acknowledge that it may not be possible to implement best practice in each survey due to fieldwork constraints, budget or partner capacity, but these choices should be taken with as much information on tradeoffs as possible.

The reference questionnaire discussed and appended to this document is designed to provide a detailed understanding of agricultural activities. The thoroughness of this questionnaire, however, may not be necessary or desired in contexts where agriculture makes up only a marginal share of the overall economy. In such cases where agriculture is not the focus of the survey or where it makes up a small share of household income, it is likely still necessary to collect some data on agriculture, if only to allow computation of total household incomes. The World Bank's LSMS team has developed an agriculture questionnaire which is designed for these cases, including only the minimum set of agricultural data necessary for analyzing the role of farm activities in household livelihoods. This shortened agriculture questionnaire is provided along with a reference household questionnaire and related guidebook (Oseni et al., 2020).

While the shortened version of the agriculture questionnaire includes crop, livestock, fishing, and forestry production, it of course comes with tradeoffs in topical coverage and level of detail. Data on crop production is collected at the parcel level, rather than at the plot level, which shortens the questionnaire but eliminates the ability to conduct plot-level productivity analysis. By aggregating to the parcel level, the concept of the plot manager, which is often used to conduct gender-related analysis, is also omitted. Details on non-labor inputs are also significantly minimized, with binary questions asked on fertilizer use rather than quantity of inputs applied, for example. No information is collected on crop processing or extension services in the shorter module. Additionally, the shortened questionnaire is designed to be implemented in a single visit, in conjunction with the household survey, rather than split into post-planting and post-harvest visits.

The tradeoffs around mode of data collection and enumerators are discussed separately in the subsequent sections.

## Piloting for Improved Survey Design

Piloting surveys in the field before implementation is an important tool to assess survey design choices. We highlight the benefits of piloting particularly when a literature on a survey design choice is thin. Incorporating methodological experiments into the pilot phase of a project is an approach to maximize the benefit of field research for projects who have already budgeted for piloting. If survey design effects are large enough to potentially bias estimates, low cost methodological experiments should be able to detect survey design biases in relatively small sized experiments.

While integrating methodological experiments into piloting provides a direct estimate of biases in survey design choices, piloting can take many forms with informative results for survey design. Piloting even with a few respondents allows survey designers and national collaborators to assess a survey instrument's ease of implementation in the field, provide a method to evaluate interviewer's understanding of the questionnaire, and identify areas of questionnaire design improvement. Field protocols can be tested during pilots and a survey's approximate duration can be estimated. During piloting, it is good to evaluate survey duration using the pilot survey duration as an upper bound on survey duration during the whole of fieldwork as interviewers will become more efficient with more questionnaire experience.

Collaborations with national partners are enhanced by integrating survey designers with national stakeholders in the piloting process. National experts in complementary disciplines can also provide insights to better design surveys tailored to respondent thinking about variables of interest for researchers. Field partner collaboration extends beyond soliciting accurate response categories for questions and into how variations in production systems within countries are best represented clearly for respondents and translated into an agricultural questionnaire design. Question phrasing that better reflects cultural context will be easier for respondents to understand and accurately report their responses.

## Mode of Data Collection

Agricultural survey data can be collected through paper-based questionnaires ("paper assisted personal interviewing" or PAPI) or tablet- or computer-based questionnaires ("computer assisted personal interviewing" or CAPI). Historically, PAPI has been the method of choice, largely for lack of alternative options. However, CAPI technologies have evolved and are now widely adopted. At the time of writing, all LSMS-ISA surveys have migrated from PAPI to CAPI implementation, using the World Bank's Survey Solutions CAPI software. Both modes of data collection come with pros and cons, though CAPI implementation is strongly recommended. PAPI implementation offers the advantage of relatively less upfront preparation time prior to fieldwork but requires significant effort in the data entry stage. In the case of PAPI implementation, it is recommended that a double-data entry approach be used in order to limit the influence of entry errors. Data entry, which can be done concurrently in the field by a designated data entry operator or at a centralized location, comes at a cost in terms of personnel and time required for data dissemination. Data quality controls in PAPI are also rather limited relative to CAPI operations. In PAPI, supervisors often review the paper questionnaire at the close of each day. If errors are found, this generally requires a re-visit to the household in order to confirm or rectify the relevant responses.

CAPI-based data collection benefits from real-time data quality controls as well as trackable revisions and supervisor review. Research from various threads of development economics have cited a reduction in errors as a result of the use of CAPI implementation, for example the Asian Development Bank (2019) on labor force data and agricultural household survey data, Fafchamps et al. (2012) on microenterprise profit data, and Caeyers et al. (2012) on consumption data. Errors that are caught in real-time, through warning messages for pre-coded errors, prompt the enumerator to confirm or correct relevant inputs at the moment the question is asked, thereby increasing data quality and limiting the need to revisit the household. Data quality can be increased at the micro level, but also at the macro level through various survey management tools that allow office-based personnel to effectively monitor operations and data quality in real time. With relatively minimal investment, survey management tables and graphics can also be automated through application programming interfaces (APIs). An additional advantage of CAPI is the possibility of developing and administering interviews in different languages, allowing interviewers to toggle between different languages as necessary to accommodate respondents. Implementation via CAPI requires additional preparation time in order to test the application and program error checks, but it can significantly decrease the time from the close of fieldwork to data dissemination as data entry is not needed and data quality controls can be implemented continuously throughout fieldwork. Numerous open-source and private CAPI software options exist, common platforms include the World Bank's Survey Solutions software, SurveyCTO, Open Data Kit (ODK), CSPro and SurveyBee. The questionnaires found in Appendix I and II are also publicly available in Survey Solutions.

With the rate of mobile phone ownership growing globally, the potential for phone-based or phone-assisted surveys increases. While national-scale agricultural data collection through phone surveys has yet to be implemented, recent methodological research on the topic has shown promise for improving data quality in some areas, while the flurry of phone surveys implemented in the face of the COVID-19 pandemic shows promise for feasibility of implementation. Methodological research on agricultural labor data collection in Tanzania, for example, shows consistent data collected through weekly in-person visits, considered to be the gold standard, and weekly phone calls, suggesting that phone surveys could be a reasonable alternative (Arthi et al., 2018). Implementation of surveys via mobile phone will necessitate simplification of the questionnaire instrument and careful assessment of mobile phone coverage in the population of interest. Further research is needed in order to fully understand the risks and challenges of phone-based national-level agricultural survey data collection.

## Fieldwork Organization and Logistics

Several features of fieldwork organization and logistics can impact data quality outcomes, including the composition, training, and structure of fieldwork teams. Fieldwork organization should include a supervisory hierarchy, with several field teams deployed, each including a set of enumerators and a supervisor, and a separate headquarters-based supervisory team which conducts periodic field supervision and continuous data review. Where a panel approach is employed, a specialized tracking team can be deployed with the objective of tracking and interviewing respondents that have relocated between survey rounds and/or split off from previous households and created new *split-off* households.[^9] In designing fieldwork structure, enumerators may be mobile (moving with teams from enumeration area to enumeration area) or resident (permanently residing in or close to the enumeration area for which s/he is responsible). The survey-structure and objectives of the survey should help to inform the fieldwork structure. Where multiple visits are necessary, such as when crop-cutting is to be implemented, resident enumerators may be more cost-efficient and effective.

At the base of the data generating process is the enumerator who manages the collection of data from respondents. A meta-analysis of the literature[^10] establishes that enumerator behavioral traits and demographic characteristics influence survey responses and by extension data quality. Response rates and response biases are particularly influenced by specific enumerator characteristics (age, sex, ethnicity, experience, education, etc.), behaviors (formal versus conversational interview style), cognitive and non-cognitive skills (such as mathematical ability, reading, attention to detail, and empathy) and interviewer experience[^11]^,^[^12]^,^[^13]. Recent research on enumerator effects by Di Maio and Fiala (2019), through a randomized experiment in Uganda, illustrate that enumerator characteristics and their differences from respondent characteristics affect survey responses and ultimately data quality, especially related to sensitive political topics. Responses in less sensitive topics were much less, or not at all, sensitive to enumerator characteristics. This is supported by additional research which suggests that salience and sensitivity of the questions at hand influence the nature and magnitude of enumerator effects (for example, Himelein, 2016; Laajaj and Macours, 2017). Beaman et al. (2018) find referral-based recruitment may disadvantage women in an enumerator recruitment experiment in Malawi. Marx et al. (2018) provide evidence on team composition and ethnic diversity on enumerator performance. Data on time use of field teams suggests horizontally homogenous teams (enumerator teams) organized tasks more efficiently, while vertically homogenous teams (supervisors, enumerators, data monitors) had lower effort. Additional research is needed to gauge the sensitivity of agricultural data specifically to enumerator characteristics.

The capacity of enumerators should also be carefully assessed to ensure they possess the skills needed for the specific survey operation, with an eye for the data collection mode being employed. Some literature exists to suggest that enumerator recruitment and contract structure affect data quality and enumerator job performance. For agricultural surveys, knowledge of farming may prove to be an asset in terms of both understanding the questionnaire content and establishing rapport with respondents. This should be weighed against enumerator education, language skills, and familiarity with technological tools (in the case of CAPI implementation).

Effective survey implementation relies on a homogenous, thorough understanding of the questionnaire content and concepts. Training of field teams, as well as those involved in survey management at the headquarters level, is essential in developing this thorough understanding. Depending on the number of people involved and the structure of the NSO or other implementing agency, training can be conducted in a single centralized location or in several parallel decentralized training locations. Centralized trainings benefit from consistent messaging for all trainees, though may be ineffective if there is a large number of trainees. Decentralized trainings are often necessitated by large groups of trainees and/or decentralized statistical offices, though they come with the complication of ensuring discussions and questionnaire revisions are communicated across locations. Irrespective of the number of training locations, a training should be held prior to each survey visit (one training for the post-planting visit and one for the post-harvest visit, in the case of a two-visit survey). Prior to each training, a "training of trainers" is commonly held, especially in the case of decentralized trainings, in order to train the facilitators of the field team trainings and ensure the implementation and concepts are clear and harmonized prior to the full training. Training of trainers, and potentially fieldwork trainings, could also be held virtually in-part, if the context allows.

Fieldwork training should be inclusive of all facets of fieldwork, from protocols on conduct with respondents to questionnaire content to data review, revision, and submission. This generally requires both classroom-style training on relevant concepts, questionnaire content and layout, and CAPI software, if applicable. Classroom instruction should be complemented by mock interviews, both amongst the enumerators themselves and with pilot households, and training on objective measures that are being integrated into the survey. For example, training on the use of GPS devices for area measurement requires theoretical training in the classroom followed by repeated practice outside the classroom.[^14] While the integration of objective measures is intended to reduce subjectivity in responses, training is still required to realize their maximum benefit.

Finally, enumerator activities should continue to be monitored throughout fieldwork. Supervision is particularly important at the onset of fieldwork, to identify and correct any misunderstandings, but is relevant for the full duration. Incoming data should be monitored both by supervisors in the field and the survey management team at the headquarters level, made quicker and more automated through the use of various CAPI tools. Additionally, supervisors from both the field and headquarters should conduct random spot checks or call backs to households to confirm data entered by enumerators matches that reported by the household.

## Plot Visits and Georeferencing

An additional layer of consideration for the design and implementation of an agricultural survey is whether visitation to agricultural plots (or parcels) will be carried out. Visitation of agricultural plots, whereby an enumerator physically travels to plots typically with a member of the sampled household or farm, enables a wide range of additional survey operations and objective measures. Crop-cutting, which has been shown to significantly reduce measurement error in agricultural production estimates, as discussed in Chapter 3, for example, requires at least two visits to the selected plots (after planting and at time of harvest). Objective measures of agricultural land area, also discussed in Chapter 3, require physical presence on the land.

In addition to the benefits of potential objective measurements, visitation of agricultural plots allows for the *georeferencing* of plots (the collection of GPS coordinates of the plots and/or the identification of the boundaries of the plots), which can add significant value through the integration with other geospatial and remotely-sensed data sources such as data on soil properties, forest coverage, climate, and water quality, among many others. Integration of these properties with data on farming practices and outcomes can provide more complete insights into the agricultural landscape and barriers to increased productivity.

Integration of agricultural survey data with various types of spatial and Earth observation data, possible with the georeferencing of plots, has expanded the scope of analysis possible with the use of survey data, while also improving the performance prediction algorithms employed in spatial analyses. In recent years there has been growing demand for crop yield estimation via remotely sensed imagery, for example, for more frequent and rapid assessment of production estimates when agricultural surveys or censuses are not available. Recent research has cited improvements in yield estimation when estimation algorithms are calibrated on ground-based crop-cutting data collected though agricultural surveys. Lobell et al. (2019) find that calibration based on crop-cutting data from Uganda significantly limited the overestimation bias observed in the uncalibrated model of maize yields. Related research by Lobell et al. (2020) highlight the possibility of sub-sampling of crop-cutting-based production measurement, whereby only a strategically selected subsample of plots are subject to crop-cutting rather than the full sample, could be sufficient to calibrate satellite-based estimation models. This would greatly improve the feasibility of scale-up in national survey operations.

While georeferencing of agricultural plots is strongly recommended when feasible, considerations need to be made to protect the confidentiality of survey respondents. GPS coordinates should not be disseminated to the public without an anonymization procedure.[^15] Anonymization, or *offsetting*, of GPS coordinates will reduce the precision of the coordinates and therefore limit the value of integrated data sources through loss of variation at the local level. With raw GPS coordinates one is able to extract climate or soil conditions for that particular point, for example, whereas offset coordinates are commonly provided at the enumeration area level and thus the data extracted from geospatial data will be the same across the enumeration area. To maximize the value of integration with geospatial data sources while preserving respondent confidentiality, the LSMS-ISA prepares and disseminates a set of *geovariables* that are derived from the raw GPS coordinates, but does not release the raw coordinates themselves. Additional research is ongoing with respect to further ways of maximizing the use of georeferenced data while maintaining confidentiality. An active literature on creating synthetic data from confidential data may provide some insights to data integration challenges (see for example, Abowd and Schmutte 2019).

